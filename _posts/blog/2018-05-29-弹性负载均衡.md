---
layout: post
title: 弹性负载均衡
categories: blog
description: 负载均衡是保障应用高可用高负荷的重要手段，小小的试用下弹性负载均衡
---


一、负载均衡简单介绍和理解
架设企业应用一般，前端安全设备防火墙等过滤网络攻击；
只有负载均衡为应用提供负荷分担技术，再后端即为企业应用

负载均衡分为软件负载均衡和硬件负载均衡
硬件负载均衡常见设备为F5
负载均衡软件最常见的Haproxy，Nginx，Lvs等等；
当然公有云上的负载均衡，不是简简单单使用以上软件实现的。但是负载均衡模型一致。

负载均衡通俗易懂的讲就是将一组同质的后端服务器提供的服务，通过负载均衡对外的IP和端口提供出去；

二、开始实验
1、实验开始前，我们先准备两台ECS服务器，服务器均没有绑定弹性IP，然后在每台ECS服务器都部署tomcat以及tomcat默认webapp；如下图所示：
![](/images/pubcloud/twoecswithouteip.jpg)

2、创建弹性负载均衡
创建之前先仔细来看下负载均衡模型，模型上可以简单理解分为前端和后端；
前段即为对外提供服务的IP地址，可以是公网也可以是私网IP，总之对外呈现的IP；
后端也就是监听器，一个负载均衡可以添加多个监听器；
看看监听器的重点属性：
2.1、负载均衡协议/端口：即该监听器关联的一组云服务器对外提供服务的端口，由于tomcat服务器默认装好后，http端口为8080，但是我们对外提供服务的时候，希望使用80端口；故此处配置80
2.2、云服务器协议/端口：即该监听器关联的一组云服务器中提供服务的端口，根据上一行，此处为8080
2.3、负载方式:即负载均衡根据什么规则将一个外部请求调度到所关联的一组服务器上的具体某一个。负载方式一般有几种：源IP方式，轮询算法，最少链接这几种
2.3.1、轮询算法：就后端服务器排队一个一个来的意思，将新链接依次分配给后端的下一个服务器；而会话保持就是指通过识别做客户与服务器之间交互过程的关连性，保证一系列相关连的访问请求会保持分配到一
台服务器上。
2.3.2、源IP方式：保障从同一个地址的请求被固定的分配到一个后端服务器上
2.3.3、最少链接：将新请求调度到当前后端服务器中最闲的一个
2.4、健康检查配置：要保障客户端的每次请求都能被有效处理，故负载均衡要实实时知后端一组服务器的状态，该状态的检测即为健康检查；大白话：配置一下每隔多久探测一下后端服务器的某个端口是否有响应，
如果若干次没响应后就认为该服务器已挂。新请求将不会再次调度到该服务器；
2.5、监听器关联的一组云服务器：就是一组同质服务器，每一个都能提供同样的服务；这就要求服务器是无状态的；

创建好的负载均衡如下图：  
![](/images/pubcloud/elb.jpg)  

![](/images/pubcloud/listener.jpg)

![](/images/pubcloud/selectedserver.jpg)


3、通过负载均衡IP访问tomcat服务  
![](/images/pubcloud/tomcatview.jpg)
![](/images/pubcloud/tomcatvisit.jpg)  
